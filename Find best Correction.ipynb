{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037c2785",
   "metadata": {},
   "source": [
    "We consider the problem of determining the most probable correction of a word not found in a dictionary. Thus, the problem is to find the correction c, among all possible candidate corrections, which maximizes the probability that c is the desired correction, given the original word w: argmax c∈ candidates P(c|w). By Bayes' theorem, this is equivalent to:\n",
    "argmax c∈ candidates P(c) P(w|c) / P(w)\n",
    "Since P(w) is the same for each possible candidate c, we can eliminate it, which gives: argmax c ∈ candidates P(c) P(w|c)\n",
    "The elements of this equation are: Language model: P(c) The probability that c appears as a word in an English text.\n",
    "Error model: P(w|c) The probability that w was typed in a text when the author meant to write c. For example, P(teh|the) is relatively high, but P(theeexyz|the) would be very low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029dc9f",
   "metadata": {},
   "source": [
    "### Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d325631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcc025",
   "metadata": {},
   "source": [
    "## 1 - Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea171af",
   "metadata": {},
   "source": [
    "###  process_data(corpus_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d54a17",
   "metadata": {},
   "source": [
    "1- Implement the process_data(corpus_file) function which allows you to :\n",
    "\n",
    "        -read the given corpus in the form of a text file, \n",
    "        -convert the text to lowercase and segment the text and returns the list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b5c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        A file_name which is found in your current directory. You just have to read it in. \n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus (text file you read) in lower case. \n",
    "    \"\"\"\n",
    "    words = [] \n",
    "\n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fedf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_data(\"big.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0fa1e",
   "metadata": {},
   "source": [
    "### get_vocabulary(corpus_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80bcbcf",
   "metadata": {},
   "source": [
    "2- Implement the function get_vocabulary(corpus_file) which :\n",
    "        \n",
    "        returns the vocabulary constructed from a corpus passed as an argument to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10d9a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(corpus_file):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        corpus_file: path to the corpus file\n",
    "    Output:\n",
    "        vocabulary: a set containing all unique words in the corpus\n",
    "    \"\"\"\n",
    "    words = process_data(corpus_file)\n",
    "    \n",
    "    vocabulary = set(words)\n",
    "    \n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7749441",
   "metadata": {},
   "source": [
    "## 2- Build the language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65342a6",
   "metadata": {},
   "source": [
    "We can estimate the probability of a word, by counting the number of times that word appears in a large corpus of text and dividing over the corpus size. Write a function that builds the language model by calculating the probability of each word based on the big.txt file provided with this lab and stores the result in an appropriate data structure. Don't forget to preprocess with the process_data function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6468b",
   "metadata": {},
   "source": [
    "### get_count(word_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86830543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word_l):\n",
    "    '''\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus. \n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    '''\n",
    "    \n",
    "    word_count_dict = {} \n",
    "    for word in word_l:\n",
    "        if word in word_count_dict:\n",
    "            word_count_dict[word]+=1\n",
    "        else:\n",
    "            word_count_dict[word]=1\n",
    "            \n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b391f",
   "metadata": {},
   "source": [
    "### get_probs(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57bdb9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    probs = {}  \n",
    "    \n",
    "    total_count=sum(word_count_dict.values())\n",
    "    for word , count in word_count_dict.items():\n",
    "        probs[word]= count/ total_count\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f90de6",
   "metadata": {},
   "source": [
    "### build_language_model(corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4fdb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_language_model(corpus_file):\n",
    "    \"\"\"\n",
    "    Build a language model by calculating the probability of each word based on the corpus file.\n",
    "    \n",
    "    Args:\n",
    "    - corpus_file: Path to the corpus file\n",
    "    \n",
    "    Returns:\n",
    "    - language_model: Dictionary containing word probabilities\n",
    "    \"\"\"\n",
    "    vocabulary=get_vocabulary(corpus_file)\n",
    "    \n",
    "    word_count_dict = get_count(vocabulary)\n",
    "    \n",
    "    language_model = get_probs(word_count_dict)\n",
    "    \n",
    "    return language_model\n",
    "\n",
    "corpus_file = \"big.txt\"\n",
    "language_model = build_language_model(corpus_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad318e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#language_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82224bb",
   "metadata": {},
   "source": [
    "## 3- Edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b04bb",
   "metadata": {},
   "source": [
    "Write the following functions:\n",
    "\n",
    "    - edits1(s): which returns the set of all strings (whether they are words or not) that can be obtained with a single modification (insertion, substitution or deletion) to be performed on the string s.\n",
    "    - edits2(s): which returns the set of all strings (whether they are words or not) which can be obtained with 2 modifications (insertion, substitution or deletion) to be carried out on the string s.\n",
    "    - knownWord(words) which filters the words from the words list which are not in the dictionary (it therefore only keeps valid words). We can use the function get_vocabulary(corpus_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17712c12",
   "metadata": {},
   "source": [
    "but before implementing the edits functions , let's implement each edit itself ( delete , switch , insert , replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686ebc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word for which you will generate all possible words \n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    \n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l=[(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    delete_l=[L+R[1:] for L,R in split_l if R]\n",
    "    \n",
    "\n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return  delete_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77576139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    ''' \n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    for L, R in split_l:\n",
    "        if len(R) >= 2:\n",
    "            switched_word = L + R[1] + R[0] + R[2:]\n",
    "            switch_l.append(switched_word)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "    \n",
    "    return switch_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca58c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l=[(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    replace_set= set()\n",
    "    for L, R in split_l:\n",
    "        for letter in letters:\n",
    "            if R:\n",
    "                replace_set.add(L+letter+R[1:])\n",
    "\n",
    "                \n",
    "    replace_set.discard(word)    \n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "777bacd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    split_l=[(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    for L, R in split_l:\n",
    "        for letter in letters:\n",
    "            \n",
    "            inserted_word= L + letter +R \n",
    "            insert_l.append(inserted_word)\n",
    "    \n",
    "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    \n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dedb2e",
   "metadata": {},
   "source": [
    "### edit_one_letter(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79dbca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    \n",
    "    edits_one = delete_letter(word) + replace_letter(word) + insert_letter(word)\n",
    "    if allow_switches:\n",
    "        edits_one += switch_letter(word)\n",
    "    edit_one_set.update(edits_one)\n",
    "    \n",
    "    return set(edit_one_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59de96",
   "metadata": {},
   "source": [
    "### edit_two_letters(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb08aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letters(word, allow_switches=True):\n",
    "    \"\"\"\n",
    "    Generate all possible edits with two modifications for the given word.\n",
    "    \"\"\"\n",
    "    edit_two_set = set()\n",
    "    \n",
    "    # Get all edits with one modification\n",
    "    edits_one = delete_letter(word) + replace_letter(word) + insert_letter(word)\n",
    "    if allow_switches:\n",
    "        edits_one += switch_letter(word)\n",
    "    \n",
    "    # For each modified word from edits_one, get all edits with one modification again\n",
    "    for edit in edits_one:\n",
    "        edits_two = delete_letter(edit) + replace_letter(edit) + insert_letter(edit)\n",
    "        if allow_switches:\n",
    "            edits_two += switch_letter(edit)\n",
    "        edit_two_set.update(edits_two)\n",
    "    \n",
    "    return edit_two_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d2781f",
   "metadata": {},
   "source": [
    "### knownWord(words, corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76efd904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knownWord(words, corpus_file):\n",
    "    \"\"\"\n",
    "    Filter words from the list 'words' that are present in the vocabulary obtained from the corpus file.\n",
    "\n",
    "    Args:\n",
    "    - words: A list of words to filter.\n",
    "    - corpus_file: The path to the corpus file used to obtain the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "    - A list containing only the words that are present in the vocabulary.\n",
    "    \"\"\"\n",
    "    # Get the vocabulary from the corpus file\n",
    "    vocabulary = get_vocabulary(corpus_file)\n",
    "    \n",
    "    # Filter words to keep only those present in the vocabulary\n",
    "    known_words = [word for word in words if word in vocabulary]\n",
    "    \n",
    "    return known_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b0545",
   "metadata": {},
   "source": [
    "## 4- Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a8e15",
   "metadata": {},
   "source": [
    "We assume that we do not have data to construct the error model, so we will adopt the following assumptions: all known words with an edit distance of 1 are infinitely more likely than known words with an edit distance d edition of 2, and infinitely less probable than a known word with an edition distance of 0. Thus, to select the most probable candidates we consider their probabilities according to the previously constructed language model and their priorities according to their edit distance from the original word. With this simplification, we do not need to multiply by a factor P(w|c), because each candidate for the chosen priority will have the same probability.\n",
    "Write the candidate(word) function which returns the first non-empty list of candidates in order of priority:\n",
    "\n",
    "    The original word, if known; Otherwise\n",
    "    The list of known words at an edit distance of one, if any; Otherwise\n",
    "    The list of known words at an edit distance of two, if any; Otherwise\n",
    "    The original word, even if it is not known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17a6c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary=get_vocabulary(corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b73eaf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates(word):\n",
    "    \"\"\"\n",
    "    Generate candidate words for the given word based on the described prioritization.\n",
    "\n",
    "    Args:\n",
    "    - word: The original word for which candidates are generated.\n",
    "\n",
    "    Returns:\n",
    "    - A list of candidate words prioritized according to the described criteria.\n",
    "    \"\"\"\n",
    "    if word in vocabulary:\n",
    "        return [word]\n",
    "    \n",
    "    candidates_one_edit = edit_one_letter(word)\n",
    "    known_candidates_one_edit = knownWord(candidates_one_edit, corpus_file)\n",
    "    known_candidates_one_edit = [candidate for candidate in known_candidates_one_edit if candidate in language_model]\n",
    "    if known_candidates_one_edit:\n",
    "        return sorted(known_candidates_one_edit, key=lambda x: language_model.get(x, 0), reverse=True)\n",
    "    \n",
    "    candidates_two_edits = edit_two_letters(word)\n",
    "    known_candidates_two_edits = knownWord(candidates_two_edits, corpus_file)\n",
    "    known_candidates_two_edits = [candidate for candidate in known_candidates_two_edits if candidate in language_model]\n",
    "    if known_candidates_two_edits:\n",
    "        return sorted(known_candidates_two_edits, key=lambda x: language_model.get(x, 0), reverse=True)\n",
    "    \n",
    "    return [word]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8689a8c",
   "metadata": {},
   "source": [
    "### Test the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "997fde78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested candidates for 'hetre':\n",
      "etre\n",
      "here\n",
      "metre\n"
     ]
    }
   ],
   "source": [
    "test_word = \"hetre\"\n",
    "\n",
    "suggested_candidates = candidates(test_word)\n",
    "\n",
    "if test_word in vocabulary:\n",
    "    print(\"Word '{}' is in the vocabulary.\".format(test_word))\n",
    "else:\n",
    "    if suggested_candidates:\n",
    "        print(\"Suggested candidates for '{}':\".format(test_word))\n",
    "        for candidate in suggested_candidates:\n",
    "            print(candidate)\n",
    "    else:\n",
    "        print(\"No candidates found for '{}'. It is not in the vocabulary and no candidates with one or two edits.\".format(test_word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce23ef27",
   "metadata": {},
   "source": [
    "Using the previous functions, write the function correction(word, k) which returns the k most probable corrections of the word word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a43caa",
   "metadata": {},
   "source": [
    "### correction(word, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f28807f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word, k):\n",
    "    \"\"\"\n",
    "    Return the k most probable corrections of the given word.\n",
    "\n",
    "    Args:\n",
    "    - word: The original word for which corrections are sought.\n",
    "    - k: The number of corrections to return.\n",
    "\n",
    "    Returns:\n",
    "    - A list of the k most probable corrections of the given word.\n",
    "    \"\"\"\n",
    "    candidates_list = candidates(word)\n",
    "    \n",
    "    sorted_candidates = sorted(candidates_list, key=lambda x: language_model.get(x, 0), reverse=True)\n",
    "    \n",
    "    return sorted_candidates[:k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e2c30",
   "metadata": {},
   "source": [
    "### Test the correction function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed1ccc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrections for 'hert':\n",
      "wert\n",
      "her\n",
      "herb\n"
     ]
    }
   ],
   "source": [
    "word = \"hert\"\n",
    "k = 3\n",
    "suggested_corrections = correction(word, k)\n",
    "print(\"Corrections for '{}':\".format(word))\n",
    "for correction_word in suggested_corrections:\n",
    "    print(correction_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe542359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'she asks met abort my age ann a told heir that a amy twenty four'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"sdhe askk mee abot my age adn I told  heer that I amm twenty four\"\n",
    "\n",
    "correct_string = []\n",
    "\n",
    "for word in string.split():\n",
    "\n",
    "    if word in vocabulary:\n",
    "        correct_string.append(word)\n",
    "        \n",
    "    else:\n",
    "        suggestions = correction(word, k=2)\n",
    "        \n",
    "        if suggestions:  \n",
    "            best_correction = suggestions[0]  \n",
    "        else:\n",
    "            best_correction = word \n",
    "            \n",
    "        correct_string.append(best_correction)\n",
    "        \n",
    "' '.join(correct_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cea7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
